<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>基于Heka，ElasticSearch和Kibana的分布式后端日志架构（一） - libisky</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="libi">
    <meta name="keywords" content="libi,golang,php,javascript"/>
    <meta name="description" content="基于Heka，ElasticSearch和Kibana的分布式后端日志架构（一）"/>
    <link href="/css/pure-min.css" type="text/css" rel="stylesheet" media="all">
    <link href="/css/blog.css" type="text/css" rel="stylesheet" media="all">
    <link href="/css/railscasts.css" type="text/css" rel="stylesheet" media="all"/>
</head>
<body class="post" data-perma="heka-elasticserach-kibana-1">
<div class="pure-g-r" id="layout">
    <div class="sidebar pure-u">
    <header class="header">
        <hgroup>
            <h1 class="brand-title">
                <a href="/" class="brand-title">libisky</a>
            </h1>
            <h2 class="brand-tagline">libi的三言两语</h2>
        </hgroup>
        <nav class="nav">
            <ul class="nav-list">
                <li class="">
                    <a href="/">文章</a>
                </li>
                <li class="">
                    <a href="/archive">归档</a>
                </li>
                <li class="">
                    <a href="/about" target="_blank" >关于</a>
                </li>
                <li class="">
                    <a href="/links" target="_blank" >友情链接</a>
                </li>
            </ul>
        </nav>
    </header>
</div>
    <div class="pure-u-1">
        <div class="content">
            <div class="post">
                <h1 class="post-header">基于Heka，ElasticSearch和Kibana的分布式后端日志架构（一）</h1>
                <div class="post-meta">
                    <small>2017-3-2</small>
                </div>
                <div class="post-description"><p>目前主流的后端日志都采用的标准的elk模式（Elasticsearch，Logstash，Kinaba），分别负责日志存储，收集和日志可视化。</p>

<p>不过介于我们的日志文件多样，分布在各个不同的服务器，各种不同的日志，为了日后方便二次开发定制。所以采用了Mozilla仿照Logstash使用golang开源实现的Heka。</p>

<h4 id="整体架构图">整体架构图</h4>

<p>采用Heka，ElasticSearch和Kibana后的整体架构如下图所示</p>

<p><img src="http://libisky.com/static/2017030201.png" alt="日志系统" /></p>

<h4 id="heka篇">Heka篇</h4>

<h5 id="简介">简介</h5>

<p>Heka对日志的处理流程为输入 分割 解码 过滤 编码 输出。单个Heka服务内部的数据流了通过Heka定义的Message数据模型在各个模块内进行流转。</p>

<p>heka内置了常用的大多数模块插件，比如</p>

<ul>
<li>输入插件有Logstreamer Input可以将日志文件作为输入源，</li>
<li>解码插件Nginx Access Log Decoder可以将nginx访问日志解码为标准的键值对数据交给后边的模块插件进行处理。</li>
</ul>

<p>得益于输入输出的灵活配置，可以将分散各地的Heka收集到的日志数据加工后统一输出到日志中心的Heka进行统一编码后交给ElasticSearch存储。</p>

<h4 id="安装">安装</h4>

<p>源码安装的方式较为繁琐这里就不再介绍，有需要可以参考官网文档。<a href="http://hekad.readthedocs.io/en/v0.10.0/installing.html">http://hekad.readthedocs.io/en/v0.10.0/installing.html</a></p>

<p>这里我们的linux发行版用的centos所以使用rpm包的安装方式。</p>

<p>下载rpm安装包</p>

<p><code>wget https://github.com/mozilla-services/heka/releases/download/v0.10.0/heka-0_10_0-linux-amd64.rpm</code></p>

<p>使用<code>rpm -i heka-0_10_0-linux-amd64.rpm</code>进行安装。</p>

<p>安装后执行 <code>hekad -version</code>输出版本号即安装成功。</p>

<h4 id="使用说明">使用说明</h4>

<p>在安装好之后使用 <code>heka -config xxx.toml</code>指定配置文件即可启动单个Heka服务。</p>

<p>配置文件内至少需要包括 输入 ，编码和输出配置。</p>

<h4 id="输入配置">输入配置</h4>

<p>因为需要收集的日志类型包括apphttp上报日志和服务器各类服务器日志，所以需要使用到输入插件包括Http Listen Input和Logstreamer Input。配置如下</p>

<h5 id="http-listen-input">Http Listen Input</h5>

<p>http listen input可以根据配置指定监听端口启动一个http服务，将日志数据post到该端口即可进行日志收集。</p>

<p>一般配置如下</p>
<pre><code class="language-toml">[HttpListenInput]
address = &quot;0.0.0.0:8325&quot; #监听当前服务器的所有接口的8325端口
auth_type = &quot;API&quot; #接口认证方式为api,需要在请求头部加入X-API-KEY方可请求成功
api_key = &quot;xxxx&quot; #设定api_key
</code></pre>

<h5 id="logstreamer-input">Logstreamer Input</h5>

<p>Logstreamer Input可以根据配置监控指定目录内的指定日志文件，在日志产生变动时会增量将新增日志数据发送给Heka服务进行日志收集。</p>

<p>一般配置如下</p>
<pre><code class="language-toml">[accesslogs]
type = &quot;LogstreamerInput&quot; 

#记录当前文件的读取位置保存目录
journal_directory = &quot;/tmp/heka&quot; 

#被监听日志文件目录 
log_directory = &quot;/var/log/nginx&quot; 

#正则匹配路径此处是匹配log_directory后面的路径,例如现在监听的文件路径为 #/var/log/nginx/2015/05/23/test.log 
file_match = '(?P&lt;Year&gt;\d+)/(?P&lt;Month&gt;\d+)/(?P&lt;Day&gt;\d+)/(?P&lt;FileName&gt;[^/]+)\.log' 

#排序,以match匹配到的年月日对文件进行排序依次监听读取 
priority = [&quot;Year&quot;,&quot;Month&quot;,&quot;Day&quot;] 

#日志的最后修改时间在oldest_duration时间后,则不会监听 
#heka 0.9.1及以前版本此处有bug,该设置无效 
oldest_duration = &quot;1h&quot; 

#分类名设置,内部是修改全局变量 Logger,以备后面对日志流做来源区分,默认则为数据处理类名 
differentiator = [&quot;FileName&quot;,&quot;-&quot;,&quot;access&quot;]

</code></pre>

<h4 id="解码设置">解码设置</h4>

<p>主要是对nginx日志和自己个性化的日志格式解码为标准的数据对象。这里用到了Nginx Access Log Decoder。</p>

<p>一般配置如下</p>
<pre><code class="language-toml">#需要在输入设置指定解码器 decoder = &quot;CombinedLogDecoder&quot; 
[CombinedLogDecoder]
type = &quot;SandboxDecoder&quot;
filename = &quot;lua_decoders/nginx_access.lua&quot;

[CombinedLogDecoder.config]
type = &quot;combined&quot;
payload_keep = true
user_agent_transform = true
log_format = '$remote_addr - $remote_user'
</code></pre>

<h4 id="编码设置">编码设置</h4>

<h5 id="elasticsearch-json-encoder">ElasticSearch JSON Encoder</h5>

<p>该插件是将之前流程处理好的数据编码后准备给后端的ElasticSearch使用。</p>

<p>配置如下</p>
<pre><code class="language-toml">[ESJsonEncoder]
index = &quot;%{Type}-%{%Y.%m.%d}&quot; //设置写入ElasticSearch的索引值
es_index_from_timestamp = true
type_name = &quot;%{Type}&quot;//设置写入ElasticSearch的分类名
    [ESJsonEncoder.field_mappings]    //映射Heka内的数据键为es json格式的key值
    Timestamp = &quot;@timestamp&quot;
    Severity = &quot;level&quot;
</code></pre>

<h4 id="输出设置">输出设置</h4>

<h5 id="elasticsearchoutput"><strong>ElasticSearchOutput</strong></h5>

<p>最后需要将Heka收集加工过的日志数据传入ElasticSearch。</p>

<p>配置如下</p>
<pre><code class="language-toml">[ElasticSearchOutput]
message_matcher = &quot;Type == 'sync.log'&quot; #设置过滤条件 无不需要过滤 设置为true即可
server = &quot;http://es-server:9200&quot; #ElasticSearch 服务地址
flush_interval = 5000 #刷新间隔
flush_count = 10 #刷新次数
encoder = &quot;ESJsonEncoder&quot; #指定编码插件
</code></pre>

<h4 id="多个heka串联设置">多个Heka串联设置</h4>

<h5 id="介绍">介绍</h5>

<p>在实际使用中因为各个服务器日志格式等不同，需要将多个heka收集后的日志数据汇总到es服务器中，我们当然可以使用直接将输出设置为es服务器地址存储，但是灵活性会大打折扣。在将来需要增加队列中间件将会无比复杂。</p>

<p>所有可以利用单个Heka作为中转，收集所有heka节点传入的日志输入统一处理输出到后端的es服务器。具体参见上面的架构图。</p>

<p>对于Heka节点间的通信使用何种协议，可以按照具体情况进行实施。</p>

<ul>
<li>如对日志数据一致性要求高，并且不允许有遗漏，可以使用TCP Output和TCP Input分别作为输出和下一节点的输入进行对接。</li>
<li>如果为了追求最大性能，允许数据有少量遗漏，则可以使用UDP Output和UDP Input分别作为输出和下一节点的输入进行对接。</li>
</ul>

<p>目前我们的日志系统主要是了收集错误及访问等日志信息，没有计费等方面的需求，所以为了节省资源。使用udp协议进行heka节点间的通讯协议。</p>

<h5 id="输出与输入配置">输出与输入配置</h5>

<p>输出配置如下</p>
<pre><code class="language-toml">[aggregator_output]
type = &quot;TcpOutput&quot;
address = &quot;next-heka-server:55&quot; #发送至后一heka节点地址
local_address = &quot;127.0.0.1&quot; #本机ip
message_matcher = &quot;TRUE&quot; #允许任何数据
</code></pre>

<p>输入配置如下</p>
<pre><code class="language-toml">[UdpOutput]
address = &quot;127.0.0.1:4880&quot; #监听端口

[UdpInput.signer.ops_0] #用来标记消息的哈希值
hmac_key = &quot;4865ey9urgkidls xtb0[7lf9rzcivthkm&quot; 
[UdpInput.signer.ops_1]
hmac_key = &quot;xdd908lfcgikauexdi8elogusridaxoalf&quot;

[UdpInput.signer.dev_1]
hmac_key = &quot;haeoufyaiofeugdsnzaogpi.ua,dp.804u&quot;
</code></pre>
</div>
            </div>
            
<div id="comment">
    
    
    <div class="row">
        <div class="ds-thread" data-thread-key="heka-elasticserach-kibana-1" data-title="基于Heka，ElasticSearch和Kibana的分布式后端日志架构（一） - libisky" data-url="http://libisy.com/2017/3/2/heka-elasticserach-kibana-1.html"></div>
        <script type="text/javascript">
            var duoshuoQuery = {short_name:"libisky"};
            (function() {
                var ds = document.createElement('script');
                ds.type = 'text/javascript';ds.async = true;
                ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
                ds.charset = 'UTF-8';
                (document.getElementsByTagName('head')[0]
                || document.getElementsByTagName('body')[0]).appendChild(ds);
            })();
        </script>
    </div>
</div>

        </div>
        <div class="footer">
    <p>&copy; libisky 2015
        powered by <a href="http://github.com/go-xiaohei/pugo">PuGo</a> with <a href="http://purecss.io" target="_blank">Pure</a>
    </p>
    <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?ccc79a4f6015d5bf5c3a4670eaba98d3";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>


</div>
    </div>
</div>
<script src="/js/jquery-2.1.4.min.js"></script>
<script src="/js/highlight.pack.js"></script>
<script>
    $(document).ready(function() {
        $('pre code').each(function(i, block) {
            hljs.highlightBlock(block);
        });
    });
</script>
</body>
</html>
