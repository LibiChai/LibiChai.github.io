<?xml version="1.0" encoding="UTF-8"?><rss version="2.0">
  <channel>
    <title>libisky</title>
    <link>http://libisy.com/</link>
    <description>阐述遇到的各种问题，分享踩过的各种坑，记录懒得记的各种命令</description>
    <managingEditor> (libi)</managingEditor>
    <pubDate>Thu, 02 Mar 2017 23:17:34 +0800</pubDate>
    <item>
      <title>基于Heka，ElasticSearch和Kibana的分布式后端日志架构（一）</title>
      <link>http://libisy.com/2017/3/2/heka-elasticserach-kibana-1.html</link>
      <description>&lt;p&gt;目前主流的后端日志都采用的标准的elk模式（Elasticsearch，Logstash，Kinaba），分别负责日志存储，收集和日志可视化。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;不过介于我们的日志文件多样，分布在各个不同的服务器，各种不同的日志，为了日后方便二次开发定制。所以采用了Mozilla仿照Logstash使用golang开源实现的Heka。&lt;/p&gt;&#xA;&#xA;&lt;h4 id=&#34;整体架构图&#34;&gt;整体架构图&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;采用Heka，ElasticSearch和Kibana后的整体架构如下图所示&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;img src=&#34;http://libisky.com/static/2017030201.png&#34; alt=&#34;日志系统&#34; /&gt;&lt;/p&gt;&#xA;&#xA;&lt;h4 id=&#34;heka篇&#34;&gt;Heka篇&lt;/h4&gt;&#xA;&#xA;&lt;h5 id=&#34;简介&#34;&gt;简介&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;Heka对日志的处理流程为输入 分割 解码 过滤 编码 输出。单个Heka服务内部的数据流了通过Heka定义的Message数据模型在各个模块内进行流转。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;heka内置了常用的大多数模块插件，比如&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;输入插件有Logstreamer Input可以将日志文件作为输入源，&lt;/li&gt;&#xA;&lt;li&gt;解码插件Nginx Access Log Decoder可以将nginx访问日志解码为标准的键值对数据交给后边的模块插件进行处理。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;得益于输入输出的灵活配置，可以将分散各地的Heka收集到的日志数据加工后统一输出到日志中心的Heka进行统一编码后交给ElasticSearch存储。&lt;/p&gt;&#xA;&#xA;&lt;h4 id=&#34;安装&#34;&gt;安装&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;源码安装的方式较为繁琐这里就不再介绍，有需要可以参考官网文档。&lt;a href=&#34;http://hekad.readthedocs.io/en/v0.10.0/installing.html&#34;&gt;http://hekad.readthedocs.io/en/v0.10.0/installing.html&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;这里我们的linux发行版用的centos所以使用rpm包的安装方式。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;下载rpm安装包&lt;/p&gt;&#xA;&#xA;&lt;p&gt;&lt;code&gt;wget https://github.com/mozilla-services/heka/releases/download/v0.10.0/heka-0_10_0-linux-amd64.rpm&lt;/code&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;使用&lt;code&gt;rpm -i heka-0_10_0-linux-amd64.rpm&lt;/code&gt;进行安装。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;安装后执行 &lt;code&gt;hekad -version&lt;/code&gt;输出版本号即安装成功。&lt;/p&gt;&#xA;&#xA;&lt;h4 id=&#34;使用说明&#34;&gt;使用说明&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;在安装好之后使用 &lt;code&gt;heka -config xxx.toml&lt;/code&gt;指定配置文件即可启动单个Heka服务。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;配置文件内至少需要包括 输入 ，编码和输出配置。&lt;/p&gt;&#xA;&#xA;&lt;h4 id=&#34;输入配置&#34;&gt;输入配置&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;因为需要收集的日志类型包括apphttp上报日志和服务器各类服务器日志，所以需要使用到输入插件包括Http Listen Input和Logstreamer Input。配置如下&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;http-listen-input&#34;&gt;Http Listen Input&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;http listen input可以根据配置指定监听端口启动一个http服务，将日志数据post到该端口即可进行日志收集。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;一般配置如下&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[HttpListenInput]&#xA;address = &amp;quot;0.0.0.0:8325&amp;quot; #监听当前服务器的所有接口的8325端口&#xA;auth_type = &amp;quot;API&amp;quot; #接口认证方式为api,需要在请求头部加入X-API-KEY方可请求成功&#xA;api_key = &amp;quot;xxxx&amp;quot; #设定api_key&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h5 id=&#34;logstreamer-input&#34;&gt;Logstreamer Input&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;Logstreamer Input可以根据配置监控指定目录内的指定日志文件，在日志产生变动时会增量将新增日志数据发送给Heka服务进行日志收集。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;一般配置如下&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[accesslogs]&#xA;type = &amp;quot;LogstreamerInput&amp;quot; &#xA;&#xA;#记录当前文件的读取位置保存目录&#xA;journal_directory = &amp;quot;/tmp/heka&amp;quot; &#xA;&#xA;#被监听日志文件目录 &#xA;log_directory = &amp;quot;/var/log/nginx&amp;quot; &#xA;&#xA;#正则匹配路径此处是匹配log_directory后面的路径,例如现在监听的文件路径为 #/var/log/nginx/2015/05/23/test.log &#xA;file_match = &#39;(?P&amp;lt;Year&amp;gt;\d+)/(?P&amp;lt;Month&amp;gt;\d+)/(?P&amp;lt;Day&amp;gt;\d+)/(?P&amp;lt;FileName&amp;gt;[^/]+)\.log&#39; &#xA;&#xA;#排序,以match匹配到的年月日对文件进行排序依次监听读取 &#xA;priority = [&amp;quot;Year&amp;quot;,&amp;quot;Month&amp;quot;,&amp;quot;Day&amp;quot;] &#xA;&#xA;#日志的最后修改时间在oldest_duration时间后,则不会监听 &#xA;#heka 0.9.1及以前版本此处有bug,该设置无效 &#xA;oldest_duration = &amp;quot;1h&amp;quot; &#xA;&#xA;#分类名设置,内部是修改全局变量 Logger,以备后面对日志流做来源区分,默认则为数据处理类名 &#xA;differentiator = [&amp;quot;FileName&amp;quot;,&amp;quot;-&amp;quot;,&amp;quot;access&amp;quot;]&#xA;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h4 id=&#34;解码设置&#34;&gt;解码设置&lt;/h4&gt;&#xA;&#xA;&lt;p&gt;主要是对nginx日志和自己个性化的日志格式解码为标准的数据对象。这里用到了Nginx Access Log Decoder。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;一般配置如下&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;#需要在输入设置指定解码器 decoder = &amp;quot;CombinedLogDecoder&amp;quot; &#xA;[CombinedLogDecoder]&#xA;type = &amp;quot;SandboxDecoder&amp;quot;&#xA;filename = &amp;quot;lua_decoders/nginx_access.lua&amp;quot;&#xA;&#xA;[CombinedLogDecoder.config]&#xA;type = &amp;quot;combined&amp;quot;&#xA;payload_keep = true&#xA;user_agent_transform = true&#xA;log_format = &#39;$remote_addr - $remote_user&#39;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h4 id=&#34;编码设置&#34;&gt;编码设置&lt;/h4&gt;&#xA;&#xA;&lt;h5 id=&#34;elasticsearch-json-encoder&#34;&gt;ElasticSearch JSON Encoder&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;该插件是将之前流程处理好的数据编码后准备给后端的ElasticSearch使用。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;配置如下&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[ESJsonEncoder]&#xA;index = &amp;quot;%{Type}-%{%Y.%m.%d}&amp;quot; //设置写入ElasticSearch的索引值&#xA;es_index_from_timestamp = true&#xA;type_name = &amp;quot;%{Type}&amp;quot;//设置写入ElasticSearch的分类名&#xA;    [ESJsonEncoder.field_mappings]    //映射Heka内的数据键为es json格式的key值&#xA;    Timestamp = &amp;quot;@timestamp&amp;quot;&#xA;    Severity = &amp;quot;level&amp;quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h4 id=&#34;输出设置&#34;&gt;输出设置&lt;/h4&gt;&#xA;&#xA;&lt;h5 id=&#34;elasticsearchoutput&#34;&gt;&lt;strong&gt;ElasticSearchOutput&lt;/strong&gt;&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;最后需要将Heka收集加工过的日志数据传入ElasticSearch。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;配置如下&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[ElasticSearchOutput]&#xA;message_matcher = &amp;quot;Type == &#39;sync.log&#39;&amp;quot; #设置过滤条件 无不需要过滤 设置为true即可&#xA;server = &amp;quot;http://es-server:9200&amp;quot; #ElasticSearch 服务地址&#xA;flush_interval = 5000 #刷新间隔&#xA;flush_count = 10 #刷新次数&#xA;encoder = &amp;quot;ESJsonEncoder&amp;quot; #指定编码插件&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h4 id=&#34;多个heka串联设置&#34;&gt;多个Heka串联设置&lt;/h4&gt;&#xA;&#xA;&lt;h5 id=&#34;介绍&#34;&gt;介绍&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;在实际使用中因为各个服务器日志格式等不同，需要将多个heka收集后的日志数据汇总到es服务器中，我们当然可以使用直接将输出设置为es服务器地址存储，但是灵活性会大打折扣。在将来需要增加队列中间件将会无比复杂。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;所有可以利用单个Heka作为中转，收集所有heka节点传入的日志输入统一处理输出到后端的es服务器。具体参见上面的架构图。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;对于Heka节点间的通信使用何种协议，可以按照具体情况进行实施。&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如对日志数据一致性要求高，并且不允许有遗漏，可以使用TCP Output和TCP Input分别作为输出和下一节点的输入进行对接。&lt;/li&gt;&#xA;&lt;li&gt;如果为了追求最大性能，允许数据有少量遗漏，则可以使用UDP Output和UDP Input分别作为输出和下一节点的输入进行对接。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;目前我们的日志系统主要是了收集错误及访问等日志信息，没有计费等方面的需求，所以为了节省资源。使用udp协议进行heka节点间的通讯协议。&lt;/p&gt;&#xA;&#xA;&lt;h5 id=&#34;输出与输入配置&#34;&gt;输出与输入配置&lt;/h5&gt;&#xA;&#xA;&lt;p&gt;输出配置如下&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[aggregator_output]&#xA;type = &amp;quot;TcpOutput&amp;quot;&#xA;address = &amp;quot;next-heka-server:55&amp;quot; #发送至后一heka节点地址&#xA;local_address = &amp;quot;127.0.0.1&amp;quot; #本机ip&#xA;message_matcher = &amp;quot;TRUE&amp;quot; #允许任何数据&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;输入配置如下&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[UdpOutput]&#xA;address = &amp;quot;127.0.0.1:4880&amp;quot; #监听端口&#xA;&#xA;[UdpInput.signer.ops_0] #用来标记消息的哈希值&#xA;hmac_key = &amp;quot;4865ey9urgkidls xtb0[7lf9rzcivthkm&amp;quot; &#xA;[UdpInput.signer.ops_1]&#xA;hmac_key = &amp;quot;xdd908lfcgikauexdi8elogusridaxoalf&amp;quot;&#xA;&#xA;[UdpInput.signer.dev_1]&#xA;hmac_key = &amp;quot;haeoufyaiofeugdsnzaogpi.ua,dp.804u&amp;quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;</description>
      <author>libi</author>
      <pubDate>Thu, 02 Mar 2017 23:17:33 +0000</pubDate>
    </item>
    <item>
      <title>Thrift在php框架laravel中的应用</title>
      <link>http://libisy.com/2016/7/28/thrfit_in_laravel.html</link>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;最近在项目中遇到需要跨系统调用的需求，找了很多rpc框架对比,因为其他部分项目使用了golang语言，为了考虑日后系统间调用更加灵活，所以决定使用thrift框架。&lt;/p&gt;&#xA;&#xA;&lt;h2 id=&#34;thrif简介&#34;&gt;Thrif简介&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;Thrift是一个支持跨语言(支持但不限于php,golang,java,c++,Ruby,Node.js等)支持远程调用rpc的软件框架.&lt;/p&gt;&#xA;&#xA;&lt;p&gt;Thrift定义了一个简单的数据类型和服务接口标准，在使用时只需要实现定义好需要用的数据类型与服务（近似理解成调用函数）到.thrfit文件,使用thrfit指令生成对应版本的语言即刻,在下面会说如何编写.thrfit文件&lt;/p&gt;&#xA;&#xA;&lt;h2 id=&#34;thrift在osx下的安装&#34;&gt;Thrift在osx下的安装&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;需要注意的是，thrift并不需要安装到服务器，只需要安装到你自己的开发机上，使用指令生成对应对应开发语言的代码就可以了。&#xA; 我使用的系统是osx10.10，用的最简单的homebrew安装方式，只需要一行指令即刻&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;brew install thrift&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;在等待片刻后,键入thrift命令看到thrift帮助指令即安装成功.&lt;/p&gt;&#xA;&#xA;&lt;h2 id=&#34;thrift文件定义&#34;&gt;.thrift文件定义&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;接下来我们需要根据项目需求来定义thrift文件,thrift支持的数据类型如下：&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;基本类型：&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;bool：布尔值，true 或 false，对应 Java 的 boolean&lt;/li&gt;&#xA;&lt;li&gt;byte：8 位有符号整数，对应 Java 的 byte&lt;/li&gt;&#xA;&lt;li&gt;i16：16 位有符号整数，对应 Java 的 short&lt;/li&gt;&#xA;&lt;li&gt;i32：32 位有符号整数，对应 Java 的 int&lt;/li&gt;&#xA;&lt;li&gt;i64：64 位有符号整数，对应 Java 的 long&lt;/li&gt;&#xA;&lt;li&gt;double：64 位浮点数，对应 Java 的 double&lt;/li&gt;&#xA;&lt;li&gt;string：utf-8编码的字符串，对应 Java 的 String&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;li&gt;结构体类型：&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;struct：定义公共的对象，类似于 C 语言中的结构体定义，在 Java 中是一个 JavaBean&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;容器类型：&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;list：对应 Java 的 ArrayList&lt;/li&gt;&#xA;&lt;li&gt;set：对应 Java 的 HashSet&lt;/li&gt;&#xA;&lt;li&gt;map：对应 Java 的 HashMap&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;异常类型：&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;exception：对应 Java 的 Exception&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&#xA;&lt;li&gt;&lt;p&gt;服务类型：&lt;/p&gt;&#xA;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;service：对应服务的类&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&#xA;&lt;p&gt;在知道大概的基础数据类型以后，我们来举个例子，假如有2个系统，分别提供用户信息服务和订单服务，订单服务在接受到订单请求时需要获取用户信息。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;根据需求，我们可以定义一个服务类叫做 user ，它提供一个getinfo函数供调用，该函数需要传入一个整型的uid，返回一个map（定义struct更为准确，这里为了演示方便使用map）,写成user.thrift文件如下所示&#xA;    namespace php user //命名空间&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;service user{&#xA;        map&amp;lt;i32,string&amp;gt; getinfo(1:i32 uid)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h2 id=&#34;代码生成&#34;&gt;代码生成&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;定义好服务（类）以后，使用thrift -r -gen 命令接口生成各个语言对应的代码版本&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;thrift -r -gen php:server user.thrift &#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;命令执行成功以后会在改目录下生成一个gen-php的目录，直接在具体项目中引入即刻。&lt;/p&gt;&#xA;&#xA;&lt;h2 id=&#34;laravel框架调用&#34;&gt;laravel框架调用&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;thrift官网提供了各个语言版本的类库供调用,项目地址：&lt;a href=&#34;https://github.com/apache/thrift/&#34;&gt;https://github.com/apache/thrift/&lt;/a&gt;&lt;/p&gt;&#xA;&#xA;&lt;p&gt;php版本使用composer依赖库进行管理,laravel集成了composer包管理，所以只需要执行&#xA;    composer require apache/thrift&#xA;即可引入成功，在其他php项目中引入请参见compser说明&lt;/p&gt;&#xA;&#xA;&lt;p&gt;引入类库以后需要继续引入上一步生成的协议代码,这里我将gen-php文件夹里的user文件夹复制到laravel的跟目录的thrift目录下，并且在composer.json中添加&#xA;    &amp;ldquo;autoload&amp;rdquo;{&#xA;        &amp;ldquo;classmap&amp;rdquo;:[&#xA;            &amp;ldquo;thrift&amp;rdquo;&#xA;        ]&#xA;    }&#xA;执行下面代码即刻引入成功&#xA;    composer dump-auto&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;laravel服务端添加代码&#34;&gt;laravel服务端添加代码&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;在laravel控制器中添加以下代码，并绑定路由&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;use Thrift\Transport\TBufferedTransport;&#xA;use Thrift\Protocol\TBinaryProtocol;&#xA;use Thrift\Transport\THttpClient;&#xA;use Thrift\Transport\TPhpStream;&#xA;header(&#39;Content-Type&#39;, &#39;application/x-thrift&#39;);&#xA;    $handler = new user();//这里是定义在服务端提供服务的类&#xA;    $processor = new \thrift\opasProcessor($handler);&#xA;&#xA;&#xA;    $transport = new TBufferedTransport(new TPhpStream(TPhpStream::MODE_R | TPhpStream::MODE_W));&#xA;    $protocol = new TBinaryProtocol($transport, true, true);&#xA;&#xA;    $transport-&amp;gt;open();&#xA;    $processor-&amp;gt;process($protocol, $protocol);&#xA;    $transport-&amp;gt;close();&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;p&gt;添加类服务定义,绑定\user\userIf接口&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;class user implements \user\userIf{&#xA;    function getinfo($uid){&#xA;        $user = User::find($uid);&#xA;        return $user;&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h3 id=&#34;laravel客户端添加代码&#34;&gt;laravel客户端添加代码&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;这里使用http协议调用远程方法，代码如下&#xA;    try {&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;        $socket = new THttpClient(&#39;www.xxx.com&#39;, 80, &#39;/thrift/server&#39;);//服务端定义的url&#xA;&#xA;        $transport = new TBufferedTransport($socket, 1024, 1024);&#xA;        $protocol = new TBinaryProtocol($transport);&#xA;        $client = new thrift\opasClient($protocol);&#xA;&#xA;        $transport-&amp;gt;open();&#xA;&#xA;&#xA;        $result = $client-&amp;gt;getinfo(1);//调用远程方法&#xA;        $transport-&amp;gt;close();&#xA;        return $result;&#xA;&#xA;    } catch (TException $tx) {&#xA;        print &#39;TException: &#39;.$tx-&amp;gt;getMessage().&amp;quot;\n&amp;quot;;&#xA;        return null;&#xA;    }&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&#xA;&lt;h2 id=&#34;其他&#34;&gt;其他&lt;/h2&gt;&#xA;&#xA;&lt;p&gt;在上面的getinfo方法返回的是一个对象,直接复制代码运行会接收不到返回值，可以修改为返回一个array(&amp;ldquo;key&amp;rdquo;=&amp;gt;&amp;ldquo;value&amp;rdquo;)数组即可。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;本文内容纯属个人理解，如有错误纰漏欢迎大家指正。&lt;/p&gt;&#xA;</description>
      <author>libi</author>
      <pubDate>Thu, 28 Jul 2016 11:52:33 +0000</pubDate>
    </item>
    <item>
      <title>新的开始</title>
      <link>http://libisy.com/2016/1/22/restart.html</link>
      <description>&lt;h3 id=&#34;惨痛教训&#34;&gt;惨痛教训&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;libisky.com在我断断续续的更新下维持了3年时间，最终因为服务器到期忘记续费，文章数据等全部丢失。懊悔之余真正认识到养成定时备份的习惯的重要性。&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;静态博客与go语言&#34;&gt;静态博客与go语言&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;博客要重新开始，在考虑了很久以后决定使用静态博客程序，使用md跟写代码一样写文章，编译生成静态文件，用户访问速度快的同时，自己也觉得感觉逼格满满。&lt;/p&gt;&#xA;&#xA;&lt;p&gt;因为对go语言的好感，所以使用了 fuxiaohei 的pugo，刚开始不久，各种特性就不在此阐述了，大家可以&lt;a href=&#34;https://github.com/go-xiaohei/pugo&#34;&gt;在此&lt;/a&gt;查看&lt;/p&gt;&#xA;&#xA;&lt;h3 id=&#34;新的开始&#34;&gt;新的开始&lt;/h3&gt;&#xA;&#xA;&lt;p&gt;从新开始以后会着重归纳日常工作中解决的问题和思路，记录常用的一些脚本命令，还有一些学习路线轨迹等。&lt;/p&gt;&#xA;</description>
      <author>libi</author>
      <pubDate>Fri, 22 Jan 2016 00:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>